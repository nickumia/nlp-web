<p><i>Foreword: The point of this series of articles is not to come up with the next generation of computer information systems.  It's just to educate on the information that is accessible by humans and not by machines.</i></p>

<p>It may seem silly but, we generally do not use our senses consciously on a day-to-day basis.  When a person is reading something, say this article for example, that person is not focused on processing the electromagnetic waves that enter their eyes.  Rather, they usually try to make sense of higher-level thinking that relates to understanding the meaning of the words they knows they are reading.  As a result, our senses are kind of on autopilot in terms of what it knows to sense.</p>

<p>If a bug jittered across the page/screen as someone was reading, it might make sense to assume that not everyone would see the bug.</p>

<h2>"Sooo.. You're saying that we can't sense something that we've never sensed before?"</h2>

<a href="https://memeguy.com/photo/48596/jackie-chan-when-i-read-i-put-on-my-thinking-cap"><img class="imgr img-responsive" style="max-width:50%; padding: 20px 20px 20px 20px;" src="https://memeguy.com/photos/images/jackie-chan-when-i-read-i-put-on-my-thinking-cap-48596.png" alt="" title="Jackie Chan - When I read I put on my thinking cap" /></a>

<p>Actually, what I'm saying is that even how our senses learn to learn about the world around us is out of our control at times.  To clarify, there are times when we have our "thinking caps" on and are in a mindset to experience the world in a new, explorative way.  When this happens, we choose to hone in and look at the lower-level thought constructs that enable and influence our high-level thinking.</p>

<p>But.. I don't think that we, as individual humans, question our eyes when we perceive the color green, or our skin when we feel something smooth, or even our our tongues when we taste something burnt.  In other words, we often look to categorize new things in terms of what we know more than we actually create new categories in which things fit.  While this isn't the most interesting revelation, it is important to keep in mind when we analyze new words or new ideas.  And <b>every word is a "new" word when it is encountered in a different context.</b></p>

<p>For the rest of the article, I want to touch upon each of the five sense, how they relate to humans and what they would mean for a machine.  And we'll start by..</p>

<h2>Listening to the World</h2>

<p>I watched a rather interesting TED Talk about <a href="https://go.ted.com/CocT">What should electric cars sound like</a> where Renzo Vitale discussed how he is working to give a "voice" to electric cars because governments believe that their silence is deadly.  <b>This is interesting, not only because we have <a href="https://www.theguardian.com/environment/2018/may/06/new-law-combats-silent-menace-electric-cars">laws</a> that will change how we perceive the world, but because it's.. kind of hard to talk about the sounds we hear from a nonhuman perspective.</b></p>

<p>Sound is ubiquitous in the universe.  Birds chirp.  Humans speak.  <!-- The wind howls/whispers/moans. -->  Electricity buzzes.  Lightning creates thunder.  The list is endless.  But, what sound does snow make?  What about a dog whistle?  While we can't classify what we can't hear, it seems we also make sense of new things as they relate to humans.  Electric cars can't be heard by their fellow street cohabitants so we say that the cars need to produce sound to alert others of its presence.</p>

<p>I'd like to pose the question of: <i>What does a horn sound like?</i></p>

<p><i>(... ponder that for a bit ...)</i></p>

<p>I know you're reading this, but try to actually think about it haha</p>

<p>I don't think there's an exact definition of "a horn needs to be within a specified range of frequencies at a certain loudness.." or anything else like that.  A horn can sound like a lot of things.  The same goes for the sound of the engine or the tires or any other moving parts in the car.  It all just sounds like a car.  (Or at least it did.)  Now, we will have a new classification of electric cars vs. mechanical cars.</p>

<p>Why is this important?  It's because our physical bodies perceive sound in terms of vibration.  We are looking to hijack how this stimulus operates and, in effect, how we react to this stimulus.  The meaning of this sound we hear will be biased before its birth, which begs the question of, <i>what gives sound meaning? The source of the sound? Or humans?</i></p>

<p>Our ears pick up on the vibrations of the environment and <a href="https://www.hearinglink.org/your-hearing/about-hearing/how-the-ear-works/">somehow</a>, <a href="https://www.nidcd.nih.gov/health/how-do-we-hear">someway</a> or <a href="https://www.medicalnewstoday.com/articles/321179.php">the other</a> process that into electrical signals, what our brains understand as sound.  We then understand some of those sounds as words/language.  This is probably the only sense in which computers operate (on a low level) identically to humans.  Sound waves vibrate an <a href="https://www.mediacollege.com/audio/microphones/how-microphones-work.html">electro-mechanical device</a> that creates an electrical signal that computers understand as sound.</p>

<p>Currently, this is where the similarities end because computers generally do not do anything to understand the prosody of a particular sound.  (Which has it's positives and negatives.) Most of which will be analyzed and discussed in the subsequent layers.  <b>The main takeaway though is that humans and machines receive the same data and this data needs to persist processing.</b>  We just need to get machines to process it to the level that humans do.</p>

<h2>Seeing the World</h2>

<p>Unlike with the previous sense, cameras do not work exactly in the same way as our eyes.  Cameras are digital. (Film cameras are not used in modern applications and, therefore, do not count haha.)  Even though I want to believe our eyes are more analog than digital, apparently <a href="https://www.quora.com/Is-the-human-brain-analog-or-digital/answer/Paul-King-2">"The brain is neither analog nor digital, but works using a signal processing paradigm that has some properties in common with both."</a></p>

<p>Before the world was digitalized with the onset of the Information Age, it <i>was</i> <a href="https://www.recode.net/2017/5/2/15518900/digital-analog-rediscover-tactile-physical-experiences-vinyl-print">analog</a>.  As such, it would make sense that our experiences are inherently analog..  And I know this wanders into the realm of Philosophy, but <a href="https://www.sns.ias.edu/dyson">Freeman Dyson</a> has an unique statement starting at <i>1:02</i> of this <a href="https://www.edge.org/conversation/freeman_dyson-is-life-analog-or-digital">video</a>.</p>

<p>The easy way of deciding whether a sense is analog or digital would be to determine whether the brain can receive both.  If it can, it doesn't help us.  If it can't, well, that means that all of the information from our senses need to follow a single scheme.  There's an article on the <a href="https://www.technologyreview.com/s/522066/solving-the-neural-code-conundrum-digital-or-analog/">MIT Technology Review</a> that states this very nicely,</p>

<blockquote class="blockquote">"The difficulty is in telling these two apart since they both depend on the pattern of spikes that travel along a neuron. And that causes much dispute in the neuroscience community because nobody agrees on when a signal is analog or digital."</blockquote>

<p>While that is from 2013, I don't think that we've narrowed down the answer any more in recent years. <b>In the end, I think we're stuck with a pixelated understanding of the world which might not be all that bad.</b>  It might be easier to textually label pixels than to figure out an alternative <!--the world to incorporate this sense into information-->.</p>

<p><small><i>Upon rereading this, I realized that I never explained how computers make sense of the data presented to them by cameras.  Besides that being out of the scope of this NLP work, there is much too much to explain.  It may make a future blog post. <:</i></small></p>
<!-- <p>, but to illustrate the point, I've create this chart of numbers, 0-255 for analog, 0-1 for digital and &infin; for neither</p>

<table>
  <thead>
      <td>Year</td>
      <td>Analog</td>
      <td>Digital</td>
      <td>Neither</td>
  </thead>
  <tbody>
    <tr>
      <td>2013</td>
      <td><a href=""></a></td>
      <td><a href=""></a></td>
      <td><a href=""></a></td>
    </tr>
    <tr>
      <td>2014</td>
      <td><a href=""></a></td>
      <td><a href=""></a></td>
      <td><a href="https://www.youtube.com/watch?v=JLT6omWrvIw">&infin;</a></td>
    </tr>
    <tr>
      <td>2015</td>
      <td><a href=""></a></td>
      <td><a href=""></a></td>
      <td><a href=""></a></td>
    </tr>
    <tr>
      <td>2016</td>
      <td><a href=""></a></td>
      <td><a href=""></a></td>
      <td><a href=""></a></td>
    </tr>
    <tr>
      <td>2017</td>
      <td><a href=""></a></td>
      <td><a href=""></a></td>
      <td><a href=""></a></td>
    </tr>
    <tr>
      <td>2018</td>
      <td><a href=""></a></td>
      <td><a href=""></a></td>
      <td><a href="https://erpinnews.com/is-the-human-brain-analog-or-digital">&infin;</a></td>
    </tr>
  </tbody>
</table> -->

<h2>"Touching?" the World</h2>

<p>This is where things start to get a bit fuzzy and it's not always a good, soft, welcoming fuzzy.  Humans have "touch sensors" at virtually every point of the surface of their body.  I am not an expert, but I will refer you to this <a href="https://learning-center.homesciencetools.com/article/skin-touch/">nice explanation</a> which raises the point that there are FOUR main types of receptors (essentially classifications, hopefully you're seeing a trend here):</p>

<ol><i>
  <li>Mechanoreceptors: things like physical displacement (pressure) and surface/contact types (texture)</li>
  <li>Thermoreceptors: things like temperature differences</li>
  <li>Pain Receptors: things like pain (not very descriptive, I know)</li>
  <li>Proprioceptors: things like positional reference between what was touched and everything around it</li></i>
</ol>

<p>The problem with classifications are that they are "almost" never 100% complete.  I believe that computers only have sensing capabilities for the first two types, namely <a href="https://en.wikipedia.org/wiki/Tactile_sensor">tactile sensors</a> and <a href="https://www.electronics-tutorials.ws/io/io_3.html">varying temperature sensors</a>.  By virtue of knowing where the sensor is installed in real-life, the information obtained  by the fourth type of sensor is inherent in building a system.</p>

<p>Because this sense is still far from being incorporated in computer NLP applications, I will end this discussion here.  <b>But it's still important to note that one thing that sets us apart as humans is our ability to be physically aware and present in a situation.  Computers do not know what that feels like.</b></p>

<h2>Smelling.. no,no.. Tasting? the World</h2>

<p>To be honest, I grouped these senses into a single category for two reasons: (1) They are both equally under-explored (mainly in terms of computers) and (2) We tend to smell things we taste and taste things we smell.</p>

<p>I was having a conversation with a friend of mine, Jacob, about senses and what it means to taste or smell something and he enlightened me to the fact that these are chemical reactions and our bodies just make sense of the inputs, outputs and byproducts of the reaction equation.</p>

<p style="text-align: center">\( \sum input = outputs + byproducts\)</p>

<!--
<p>\(a_i = b_o + u_b\) where 
  <br/> \(a_i : inputs\) 
  <br/> \(b_o : byproducts\)
  <br/> \(u_b : outputs\)
</p>-->

<p>In traditional chemistry, the inputs would be a variety of chemical elements and/or compounds and the output would be the new elements/compounds created after the reaction.  While this doesn't directly relate to how a computer might smell/taste something, it helps to explain how scents and tastes are formed.  It turns out that <a href="https://www.the-scientist.com/notebook/computers-that-can-smell-31575">the research</a> still needs to apply these chemistry principles to human-relatable terms (in an attempt to classify a smell).  This raises the age-old question of how to isolate bias from data to get a true measure of value.</p>

<p>Does the <a href="https://www.youtube.com/watch?v=D_pGQBdX55Y">Law of Large Numbers</a> weed out any variance in how badly a scent or taste is classified?  Perhaps.  But again, we end up veering out of the realm of NLP.</p>

<h2>Making sense of it all</h2>

<p>Hopefully I was able to explain the fact that computers are currently in no fit state to understand humans.  Without knowledge of each of these facilities (as relevant to the desired application), there simply isn't enough data from which to form the ideas that humans would like to believe they are forming with fancy "higher-level" algorithms.</p>

<p><i>It makes me sad when I think of the instances where systems were (are) designed with knowledge that they would be incomplete and then deployed (in sometimes very serious use cases.)</i></p>

<p>Nevertheless, once a sense is identified with its own set of characteristics, data and meaning, it can then be captured and passed along to the next step.  Each sense is unique, but needs to be parsed by a single being and analyzed with other pieces of data.  Understanding what that means to each system can be difficult and is what the next section is about.</p>
